= Alerting

== Overview

The purpose of alerting is to bring attention to significant events and issues that arise during execution of a pipeline
by sending messages via email, Slack, etc. To simplify the incorporation of alerting, pre-constructed patterns have been
developed and can be included in a https://github.com/boozallen/aissemble[Solution Baseline,role=external,window=_blank]
project. This means there are only a few steps necessary to incorporate generated code for alerting purposes. This page
is intended to explain the generated components that are included when alerting is enabled, and determining where to
modify and customize elements to suit a specific implementation.

== What Gets Generated
Alerting is xref:pipeline-metamodel.adoc#_pipeline_metamodel[enabled by default]
for projects that have a pre-fab data delivery pipeline.

[WARNING]
Alerting is currently only available for Spark Data Delivery Pipelines and will be available for PySpark Data Delivery
and Machine Learning Pipelines in a future version.

=== Default Method for Sending Alerts
When alerting is enabled, a few methods (outlined below) are generated in the base class of each step. These methods are
called automatically upon step completion (whether successfully or with an exception) to send an alert. All of these
methods have default logic, but can be customized by overriding the method in the step implementation class.

****
.sendAlerts
[source,java]
----
/**
 * Send an alert with a given status and message.
 * Override this method to customize how messages are sent to the alerting framework.
 */
protected void sendAlert(Alert.Status status, String message)
----
_Parameters:_

* `status` – the status of the alert
* `message` – the message

_Returns:_ None
****

****
.getSuccessMessage
[source,java]
----
/**
 * Returns the message sent via alerting when the step completes successfully.
 * Override this method to provide your own success message.
 */
protected String getSuccessMessage(Map<String, String> params)
----

_Parameters:_

* `params` – map of parameters for the success message including the execution duration under the key timeToComplete

_Returns:_ Success message with the action and the time to complete
****

****
.getErrorMessage
[source,java]
----
/**
 * Returns the message sent via alerting when the step throws an exception.  Override this method to provide your own
 * error message.
 */
protected String getErrorMessage(Exception e)
----

_Parameters:_

* `e` – The exception that caused the step to fail

_Returns:_ The detailed error message
****

== Configuring Your Alerting Service
The Solution Baseline provides several integration options for alerting purposes.

=== Alerting with Slack
The default alerting implementation is Slack. To use Slack Alerting, follow the steps below:

. Add the aiSSEMBLE(TM) Slack alerting dependency `extensions-alerting-slack` to the pipeline POM:
[source,xml]
----
<dependencies>
	...
	<dependency>
		<groupId>com.boozallen.aissemble</groupId>
		<artifactId>extensions-alerting-slack</artifactId>
	</dependency>
	...
</dependencies>
----

[start=2]
. Add the SlackConsumer bean to the pipeline within the PipelinesCdiContext.java file

[source,java]
----
public List<Class<?>> getCdiClassses() {
	// Add any customer CDI classes here
    ...
	customBeans.add(SlackConsumer.class)

	return customBeans;
}

----

[start=3]
. Create the slack-integration.properties in the following path:
`<project>-docker/<project>-spark-worker-docker/src/main/resources/krausening/base/slack-integration.properties`

=== Messaging Integration
The default alerting implementation can be extended to publish the alerts to a Messaging topic. Adding a
`microprofile-config.properties` file with the following configurations will enable the Messaging integration for the
default Alert Producer:

.<spark-data-delivery-pipeline>/src/main/resources/META-INF/microprofile-config.properties
[source]
----
kafka.bootstrap.servers=kafka-cluster:9093 <1>

mp.messaging.outgoing.alerts.connector=smallrye-kafka
mp.messaging.outgoing.alerts.topic=kafka-alert-topic-name <2>
mp.messaging.outgoing.alerts.key.serializer=org.apache.kafka.common.serialization.StringSerializer
mp.messaging.outgoing.alerts.value.serializer=org.apache.kafka.common.serialization.StringSerializer
----
<1> The hostname and port of the Messaging server to connect to.
<2> The name of the Messaging topic to publish the alerts to.

Please see the https://smallrye.io/smallrye-reactive-messaging/latest/kafka/kafka[SmallRye
documentation,role=external,window=_blank] on the Kafka connector for more configuration details.
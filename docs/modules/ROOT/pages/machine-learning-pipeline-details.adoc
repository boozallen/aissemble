= Machine Learning Pipeline Patterns

== Overview
To simplify the incorporation of commonly used pipeline components, pre-constructed patterns have been developed and can
be included in your project. This means that if you are adding a machine learning pipeline to your project, there are
only a few steps necessary to incorporate generated code for some major machine-learning muscle movements such as
training and inference. This page is intended to assist in understanding the generated components that are included when
using these patterns as well as assist you in determining where to modify and customize elements to suit your specific
implementation.

== What Gets Generated
For projects that have included a pre-fab machine learning pipeline, several pre-constructed elements are generated when
the project is initially built. These elements are intended to simplify the inclusion of infrastructure and scaffolding
in the project, reducing the burden on project teams to each develop and incorporate these elements. Below are some
examples of generated elements.

=== JSON
The JSON file that is generated includes details about the machine learning pipeline implemented for the project,
including the specification of steps that comprise the pipeline and other details. (for information on configuring the
json file, please check out xref:pipeline-metamodel.adoc[Detailed Pipeline Options])

.ExampleMachineLearningPipeline.json
[source,json]
----
{
	"name": "ExampleMachineLearningPipeline",
	"package": "com.boozallen.aissemble",
	"type": {
		"name": "machine-learning",
		"implementation": "machine-learning-mlflow"
	},
	"steps": [
		{
			"name": "AissembleMachineLearningTraining",
			"type": "training",
			"inbound": {
				"type": "messaging",
				"channelName": "train"
			}
		},
		{
			"name": "AissembleMachineLearningInference",
			"type": "inference"
		}
	]
}
----

//todo section seems redundant with previous documentation on the mda generation build-action-build-action loop
=== POM
After specifying the contents of the JSON file, you would then run a `./mvnw clean install` to generate the associated POM
file. An example POM file associated with the example JSON from above is shown below. Some content in the pom file
will be specific to the machine learning pipeline defined for the project.

.example-pom.xml
[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<parent>
		<groupId>com.boozallen.aissemble</groupId>
		<artifactId>my-solution-baseline-project</artifactId>
		<version>1.0.0-SNAPSHOT</version>
	</parent>

	<artifactId>example-machine-learning-pipeline</artifactId>
	<packaging>pom</packaging>

	<name>My Solution Baseline Project::Pipelines::Example Machine Learning Pipeline</name>
	<description>${pipeline.description}</description>

	<modules>
        <!-- TODO: replace with your step-specific modules here -->
	</modules>

	<build>
		<plugins>
			<plugin>
				<groupId>org.technologybrewery.fermenter</groupId>
				<artifactId>fermenter-mda</artifactId>
				<configuration>
					<basePackage>com.boozallen.aissemble</basePackage>
					<profile>machine-learning-pipelines</profile>
					<propertyVariables>
						<targetPipeline>ExampleMachineLearningPipeline</targetPipeline>
					</propertyVariables>
					<!-- see my-solution-baseline-project-pipelines for base configuration settings -->
				</configuration>
			</plugin>
		</plugins>
	</build>

</project>
----


As an output of the build, you will be prompted to add the machine learning module to the pipelines identified in your
project. An excerpt from the build output is shown below. This excerpt instructs you to add the pipeline module to
activate it in your build.

.Manual Action Excerpt
----
[WARNING] 
***********************************************************************
*** MANUAL ACTION NEEDED!                      ***
***********************************************************************
You must add the pipeline module to my-solution-baseline-project-pipelines/pom.xml to activate it in your build!

Example:
  <modules>
    <module>example-machine-learning-pipeline</module>
    <!-- Just add the above module if the <modules> tag already exists -->
  </modules>

***********************************************************************
***********************************************************************
----

You will then run another `./mvnw clean install` to activate the pipeline and generate out the training and inference
module pom files. As an output of the build, you will be prompted to add the training and inference modules to the
machine learning pipeline identified in your project. This excerpt is shown below.

.Manual Action Excerpt
----
[WARNING] 
***********************************************************************
*** MANUAL ACTION NEEDED!                      ***
***********************************************************************
You must add the step module to example-machine-learning-pipeline/pom.xml to activate it in your build!

Example:
  <modules>
    <module>aissemble-machine-learning-training</module>
    <!-- Just add the above module if the <modules> tag already exists -->
  </modules>

***********************************************************************
***********************************************************************
[WARNING] 
***********************************************************************
*** MANUAL ACTION NEEDED!                      ***
***********************************************************************
You must add the step module to example-machine-learning-pipeline/pom.xml to activate it in your build!

Example:
  <modules>
    <module>aissemble-machine-learning-inference</module>
    <!-- Just add the above module if the <modules> tag already exists -->
  </modules>

***********************************************************************
***********************************************************************
----

The next step you will need to do is add in each of the steps listed in the example output into the machine learning
pipeline pom. (e.g. `<module>aissemble-machine-learning-training</module>`,
`<module>aissemble-machine-learning-inference</module>`). Once completed, a final `./mvnw clean install` is run to
generate the scaffolding code for inference and training.

=== Inference
For our example, under the generated `aissemble-machine-learning-inference` module, the following will be generated
and will require some updates:

.Inference Items to Update
[cols="2,3a"]
|===
|File Name/Directory|Notes/Updates

|`src/aissemble_machine_learning_inference/inference_impl.py`
|This file is where the majority of inference model loading and prediction execution will be implemented.

* Add imports that are needed for your chosen type of machine learning
* Load your model using the mlflow package that corresponds to your implementation
* Add in tensorflow if you need it
* Map predictions to the desired inference format

|`src/aissemble_machine_learning_inference/inference/rest/inference_api_rest.py`
|Defines the https://fastapi.tiangolo.com/[FastAPI,role=external,window=_blank] based REST API that is exposed to
inference consumers.  Developers may modify this file as needed to customize the API, which may include adding
authentication/authorization, enabling CORS, etc.

|`pyproject.toml`
|All Python projects emitted by aiSSEMBLE are https://python-poetry.org/[Poetry,role=external,window=_blank] projects
that rely on https://github.com/TechnologyBrewery/habushu[Habushu,role=external,window=_blank] for DevOps automation.
`pyproject.toml` is a required Poetry configuration that aligns with
https://peps.python.org/pep-0518/[PEP-518,role=external,window=_blank] and defines the project's build system
requirements.  Developers should customize this configuration as needed to support additional dependencies or
capabilities required within pipelines.

|`src/aissemble_machine_learning_inference/validation/inference_payload_definition.py`
|Defines the request/response payloads that capture the format of input data records for inferencing as well as the
output format of inference results.

* You will need to make sure all expected fields that you will be using are defined here for inference requests.
Developers may also define inference payloads by specifying `inbound`/`outbound` elements within the corresponding
`inference` pipeline metamodel that reference semantic type dictionary records.

|`src/aissemble_machine_learning_inference/resources/krausening/base/inference.properties`
|This can be updated to configure different properties for your inference build

* Update the model_directory to match the path to your model.
* Add any additional properties that you may need

|`src/aissemble_machine_learning_inference/config/inference_config.py`
|This file pulls in the configurations for inference. No updates should be needed, but if you have any custom
configurations you need to setup, this file can be updated.

|`tests/features/inference.feature`
|This file comes with a basic "Hello World" feature that shows a quick example of a feature written in Gherkin. For
every feature you are trying to support and have test steps to correspond, we recommend you write a feature in this file.

* Remove the base Hello world feature (if you have other features to add)
* Add features that you need to test

|`src/test/python/features/steps/inference_steps.py`
|This is where you can write your test code that will link up to the features written in the inference.feature file

* Remove the "Hello World" steps if the feature was removed from the feature file.
* Add methods for each step that you have in your feature file
|===


=== Training
Under the `aissemble-machine-learning-training` module, the following will be generated:

.Training Items to Update
[cols="2,4a"]
|===
|File Name/Directory|Notes/Updates

|`src/aissemble_machine_learning_training/impl/example_machine_learning_pipeline.py`
|This will likely be the place where most of your work will occur. This is where you will be writing each of your
implementation code for each of the main methods:

* acknowledge_training_alert (optional)
* load_dataset
* prep_dataset
* select_features
* split_dataset
* train_model
* evaluate_model
* save_model
* deploy_model

|`src/aissemble_machine_learning_training/example_machine_learning_pipeline_driver.py`
|By default, this driver listens for the appropriate training alert and executes the training pipeline.  Developers may
update this driver based on the specifics of how training jobs should be triggered.

|`pyproject.toml`
|All Python projects emitted by aiSSEMBLE are https://python-poetry.org/[Poetry,role=external,window=_blank] projects
that rely on https://github.com/TechnologyBrewery/habushu[Habushu,role=external,window=_blank] for DevOps automation.
`pyproject.toml` is a required Poetry configuration that aligns with
https://peps.python.org/pep-0518/[PEP-518,role=external,window=_blank] and defines the project's build system requirements.  Developers should customize this configuration as needed to support additional dependencies or capabilities required within pipelines.

|`src/aissemble_machine_learning_training/generated`
|This is where your generated code will live. Nothing should be updated within this folder.

|`src/aissemble_machine_learning_training/config/pipeline_config.py`
|This file pulls in the configurations for inference. No updates should be needed, but if you have any custom
configurations you need to set up, this file can be updated.

|`src/aissemble_machine_learning_training/resources/config/pipeline.properties`
|This can be updated to configure different properties for your training build

* Add any additional properties that you may need

|`tests/features/training.feature`
|This file comes with a basic "Hello World" feature that shows a quick example of a feature written in Gherkin. For
every feature you are trying to support and have test steps to correspond, we recommend you write a feature in this file.

* Remove the base Hello world feature (if you have other features to add)
* Add features that you need to test

|`tests/features/steps/training_steps.py`
|This is where you can write your test code that will link up to the features written in the `inference.feature` file

* Remove the "Hello World" steps if the feature was removed from the feature file.
* Add methods for each step that you have in your feature file
|===

=== Model Training API

If you include a training step, a Docker build is included to execute your model training logic as a Kubernetes job
within your project cluster.

You can also optionally include a Model Training API in your project, which will allow you to create model training
jobs, list jobs, retrieve job logs, and kill jobs via HTTP requests. By default, this service will be listening on
*port 5001*.

In order to include this API in your project, include an execution in your deployment `pom.xml` pointing to the
`training-deploy` profile. More information is available on the xref:containers.adoc#_containers[Container Support page].

Here are the available routes:

POST /training-jobs?pipeline_step=\{pipelineStep}

* `pipelineStep` is the name of the "training" ML pipeline step you would like to execute
** Must be CamelCased
* The request body contains all key/value pairs required for model training, such as model hyperparameters
** You are responsible for reading in these hyperparameters within your model training script
* Functionality:
** Spawns appropriate model training Kubernetes job
*** Returns 500 error if pipeline step not present
** Returns model training job name
*** Sample response: "model-training-logistic-training-a8bfa39b-aa2b-403c-8311-f40dda"

GET /training-jobs/\{trainingJobName}

* Returns logs from pod running model training job
* Returns 400 error if job doesn't exist

GET /training-jobs

* Returns list of all model training jobs (active, failed, and completed) and statuses
* Returns 500 error if training jobs statuses cannot be retrieved
* Sample response:
[source]
----
[{'name': 'model-training-logistic-training-d20dd35d-910e-4bb0-8862-621ce7',
  'status': "{'active': None,\n"
            " 'completed_indexes': None,\n"
            " 'completion_time': None,\n"
            " 'conditions': [{'last_probe_time': datetime.datetime(2023, 5, "
            '10, 6, 41, 51, tzinfo=tzlocal()),\n'
            "                 'last_transition_time': datetime.datetime(2023, "
            '5, 10, 6, 41, 51, tzinfo=tzlocal()),\n'
            "                 'message': 'Job has reached the specified "
            "backoff limit',\n"
            "                 'reason': 'BackoffLimitExceeded',\n"
            "                 'status': 'True',\n"
            "                 'type': 'Failed'}],\n"
            " 'failed': 1,\n"
            " 'ready': 0,\n"
            " 'start_time': datetime.datetime(2023, 5, 10, 6, 41, 47, "
            'tzinfo=tzlocal()),\n'
            " 'succeeded': None,\n"
            " 'uncounted_terminated_pods': {'failed': None, 'succeeded': "
            'None}}'}]
----


GET /training-jobs?pipeline_step=\{pipelineStep}

* `pipelineStep` is the name of the "training" ML pipeline step you would like to execute
** Must be CamelCased
* For the given pipeline step, returns list of all model training jobs (active, failed, and completed) and statuses
* Returns 500 error if training jobs statuses cannot be retrieved
* Sample response:
[source]
----
[{'name': 'model-training-logistic-training-d20dd35d-910e-4bb0-8862-621ce7',
  'status': "{'active': None,\n"
            " 'completed_indexes': None,\n"
            " 'completion_time': None,\n"
            " 'conditions': [{'last_probe_time': datetime.datetime(2023, 5, "
            '10, 6, 41, 51, tzinfo=tzlocal()),\n'
            "                 'last_transition_time': datetime.datetime(2023, "
            '5, 10, 6, 41, 51, tzinfo=tzlocal()),\n'
            "                 'message': 'Job has reached the specified "
            "backoff limit',\n"
            "                 'reason': 'BackoffLimitExceeded',\n"
            "                 'status': 'True',\n"
            "                 'type': 'Failed'}],\n"
            " 'failed': 1,\n"
            " 'ready': 0,\n"
            " 'start_time': datetime.datetime(2023, 5, 10, 6, 41, 47, "
            'tzinfo=tzlocal()),\n'
            " 'succeeded': None,\n"
            " 'uncounted_terminated_pods': {'failed': None, 'succeeded': "
            'None}}'}]
----

DELETE /training-jobs/\{trainingJobName}

* Deletes specified Kubernetes job
* Returns 500 error if job does not exist
* Sample Response: "model-training-logistic-training-a8bfa39b-aa2b-403c-8311-f40dda successfully deleted."
########################################
## CONFIG | Spark Configs
########################################
metadata:
  namespace: default
sparkApp:
  spec:
    type: "placeholder" #required for a dry run test to pass, this should always be overridden
    mode: cluster
    imagePullPolicy: IfNotPresent
    restartPolicy:
      type: Never
    sparkVersion: "3.5.2"
    sparkConf:
      spark.hive.server2.thrift.port: "10000"
      spark.hive.server2.thrift.http.port: "10001"
      spark.hive.server2.transport.mode: "http"
      spark.hadoop.fs.s3a.path.style.access: "true"
      spark.hive.server2.thrift.http.path: "cliservice"
      spark.hive.metastore.schema.verification: "false"
      spark.hive.metastore.uris: "thrift://hive-metastore-service:9083/default"
      spark.eventLog.dir: "/opt/spark/spark-events"
      spark.hive.metastore.warehouse.dir: "s3a://spark-infrastructure/warehouse"
    dynamicAllocation:
      enabled: true
      initialExecutors: 0
      minExecutors: 0
      maxExecutors: 4
    volumes:
      - name: ivy-cache
        persistentVolumeClaim:
          claimName: ivy-cache
      - name: spark-events
        persistentVolumeClaim:
          claimName: spark-events-claim
    driver:
      cores: 1
      coreLimit: "1200m"
      memory: "512m"
      serviceAccount: spark
      volumeMounts:
        - name: ivy-cache
          mountPath: "/opt/spark/.ivy2"
        - name: spark-events
          mountPath: "/opt/spark/spark-events"
    executor:
      cores: 1
      coreLimit: "1200m"
      memory: "512m"
      labels:
        version: 3.5.2
      volumeMounts:
        - name: ivy-cache
          mountPath: "/opt/spark/.ivy2"
        - name: spark-events
          mountPath: "/opt/spark/spark-events"
service:
  enabled: false
  spec:
    ports:
      - name: "debug"
        port: 4747
        targetPort: 4747
